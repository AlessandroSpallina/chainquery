// This file is generated by SQLBoiler (https://github.com/lbryio/sqlboiler)
// and is meant to be re-generated in place and/or deleted at any time.
// DO NOT EDIT

package model

import (
	"bytes"
	"database/sql"
	"fmt"
	"reflect"
	"strings"
	"sync"
	"time"

	"github.com/lbryio/errors.go"
	"github.com/lbryio/null.go"
	"github.com/lbryio/sqlboiler/boil"
	"github.com/lbryio/sqlboiler/queries"
	"github.com/lbryio/sqlboiler/queries/qm"
	"github.com/lbryio/sqlboiler/strmangle"
)

// Block is an object representing the database table.
type Block struct {
	ID                    uint64      `boil:"id" json:"id" toml:"id" yaml:"id"`
	Bits                  string      `boil:"bits" json:"bits" toml:"bits" yaml:"bits"`
	Chainwork             string      `boil:"chainwork" json:"chainwork" toml:"chainwork" yaml:"chainwork"`
	Confirmations         uint        `boil:"confirmations" json:"confirmations" toml:"confirmations" yaml:"confirmations"`
	Difficulty            string      `boil:"difficulty" json:"difficulty" toml:"difficulty" yaml:"difficulty"`
	Hash                  string      `boil:"hash" json:"hash" toml:"hash" yaml:"hash"`
	Height                uint64      `boil:"height" json:"height" toml:"height" yaml:"height"`
	MedianTime            uint64      `boil:"median_time" json:"median_time" toml:"median_time" yaml:"median_time"`
	MerkleRoot            string      `boil:"merkle_root" json:"merkle_root" toml:"merkle_root" yaml:"merkle_root"`
	NameClaimRoot         string      `boil:"name_claim_root" json:"name_claim_root" toml:"name_claim_root" yaml:"name_claim_root"`
	Nonce                 uint64      `boil:"nonce" json:"nonce" toml:"nonce" yaml:"nonce"`
	PreviousBlockHash     null.String `boil:"previous_block_hash" json:"previous_block_hash,omitempty" toml:"previous_block_hash" yaml:"previous_block_hash,omitempty"`
	NextBlockHash         null.String `boil:"next_block_hash" json:"next_block_hash,omitempty" toml:"next_block_hash" yaml:"next_block_hash,omitempty"`
	BlockSize             uint64      `boil:"block_size" json:"block_size" toml:"block_size" yaml:"block_size"`
	Target                string      `boil:"target" json:"target" toml:"target" yaml:"target"`
	BlockTime             uint64      `boil:"block_time" json:"block_time" toml:"block_time" yaml:"block_time"`
	Version               uint64      `boil:"version" json:"version" toml:"version" yaml:"version"`
	VersionHex            string      `boil:"version_hex" json:"version_hex" toml:"version_hex" yaml:"version_hex"`
	TransactionHashes     null.String `boil:"transaction_hashes" json:"transaction_hashes,omitempty" toml:"transaction_hashes" yaml:"transaction_hashes,omitempty"`
	TransactionsProcessed bool        `boil:"transactions_processed" json:"transactions_processed" toml:"transactions_processed" yaml:"transactions_processed"`
	Created               time.Time   `boil:"created" json:"created" toml:"created" yaml:"created"`
	Modified              time.Time   `boil:"modified" json:"modified" toml:"modified" yaml:"modified"`

	R *blockR `boil:"-" json:"-" toml:"-" yaml:"-"`
	L blockL  `boil:"-" json:"-" toml:"-" yaml:"-"`
}

var BlockColumns = struct {
	ID                    string
	Bits                  string
	Chainwork             string
	Confirmations         string
	Difficulty            string
	Hash                  string
	Height                string
	MedianTime            string
	MerkleRoot            string
	NameClaimRoot         string
	Nonce                 string
	PreviousBlockHash     string
	NextBlockHash         string
	BlockSize             string
	Target                string
	BlockTime             string
	Version               string
	VersionHex            string
	TransactionHashes     string
	TransactionsProcessed string
	Created               string
	Modified              string
}{
	ID:                    "id",
	Bits:                  "bits",
	Chainwork:             "chainwork",
	Confirmations:         "confirmations",
	Difficulty:            "difficulty",
	Hash:                  "hash",
	Height:                "height",
	MedianTime:            "median_time",
	MerkleRoot:            "merkle_root",
	NameClaimRoot:         "name_claim_root",
	Nonce:                 "nonce",
	PreviousBlockHash:     "previous_block_hash",
	NextBlockHash:         "next_block_hash",
	BlockSize:             "block_size",
	Target:                "target",
	BlockTime:             "block_time",
	Version:               "version",
	VersionHex:            "version_hex",
	TransactionHashes:     "transaction_hashes",
	TransactionsProcessed: "transactions_processed",
	Created:               "created",
	Modified:              "modified",
}

// BlockFilter allows you to filter on any columns by making them all pointers.
type BlockFilter struct {
	ID                    *uint64      `boil:"id" json:"id,omitempty" toml:"id" yaml:"id,omitempty"`
	Bits                  *string      `boil:"bits" json:"bits,omitempty" toml:"bits" yaml:"bits,omitempty"`
	Chainwork             *string      `boil:"chainwork" json:"chainwork,omitempty" toml:"chainwork" yaml:"chainwork,omitempty"`
	Confirmations         *uint        `boil:"confirmations" json:"confirmations,omitempty" toml:"confirmations" yaml:"confirmations,omitempty"`
	Difficulty            *string      `boil:"difficulty" json:"difficulty,omitempty" toml:"difficulty" yaml:"difficulty,omitempty"`
	Hash                  *string      `boil:"hash" json:"hash,omitempty" toml:"hash" yaml:"hash,omitempty"`
	Height                *uint64      `boil:"height" json:"height,omitempty" toml:"height" yaml:"height,omitempty"`
	MedianTime            *uint64      `boil:"median_time" json:"median_time,omitempty" toml:"median_time" yaml:"median_time,omitempty"`
	MerkleRoot            *string      `boil:"merkle_root" json:"merkle_root,omitempty" toml:"merkle_root" yaml:"merkle_root,omitempty"`
	NameClaimRoot         *string      `boil:"name_claim_root" json:"name_claim_root,omitempty" toml:"name_claim_root" yaml:"name_claim_root,omitempty"`
	Nonce                 *uint64      `boil:"nonce" json:"nonce,omitempty" toml:"nonce" yaml:"nonce,omitempty"`
	PreviousBlockHash     *null.String `boil:"previous_block_hash" json:"previous_block_hash,omitempty" toml:"previous_block_hash" yaml:"previous_block_hash,omitempty"`
	NextBlockHash         *null.String `boil:"next_block_hash" json:"next_block_hash,omitempty" toml:"next_block_hash" yaml:"next_block_hash,omitempty"`
	BlockSize             *uint64      `boil:"block_size" json:"block_size,omitempty" toml:"block_size" yaml:"block_size,omitempty"`
	Target                *string      `boil:"target" json:"target,omitempty" toml:"target" yaml:"target,omitempty"`
	BlockTime             *uint64      `boil:"block_time" json:"block_time,omitempty" toml:"block_time" yaml:"block_time,omitempty"`
	Version               *uint64      `boil:"version" json:"version,omitempty" toml:"version" yaml:"version,omitempty"`
	VersionHex            *string      `boil:"version_hex" json:"version_hex,omitempty" toml:"version_hex" yaml:"version_hex,omitempty"`
	TransactionHashes     *null.String `boil:"transaction_hashes" json:"transaction_hashes,omitempty" toml:"transaction_hashes" yaml:"transaction_hashes,omitempty"`
	TransactionsProcessed *bool        `boil:"transactions_processed" json:"transactions_processed,omitempty" toml:"transactions_processed" yaml:"transactions_processed,omitempty"`
	Created               *time.Time   `boil:"created" json:"created,omitempty" toml:"created" yaml:"created,omitempty"`
	Modified              *time.Time   `boil:"modified" json:"modified,omitempty" toml:"modified" yaml:"modified,omitempty"`
}

// blockR is where relationships are stored.
type blockR struct {
	BlockHashTransactions TransactionSlice
}

// blockL is where Load methods for each relationship are stored.
type blockL struct{}

var (
	blockColumns               = []string{"id", "bits", "chainwork", "confirmations", "difficulty", "hash", "height", "median_time", "merkle_root", "name_claim_root", "nonce", "previous_block_hash", "next_block_hash", "block_size", "target", "block_time", "version", "version_hex", "transaction_hashes", "transactions_processed", "created", "modified"}
	blockColumnsWithoutDefault = []string{"bits", "chainwork", "confirmations", "difficulty", "hash", "height", "median_time", "merkle_root", "name_claim_root", "nonce", "previous_block_hash", "next_block_hash", "block_size", "target", "block_time", "version", "version_hex", "transaction_hashes", "created", "modified"}
	blockColumnsWithDefault    = []string{"id", "transactions_processed"}
	blockPrimaryKeyColumns     = []string{"id"}
	blockAutoIncrementColumn   = "id"
)

type (
	// BlockSlice is an alias for a slice of pointers to Block.
	// This should generally be used opposed to []Block.
	BlockSlice []*Block

	BlockQuery struct {
		*queries.Query
	}
)

// Cache for insert, update and upsert
var (
	blockType                 = reflect.TypeOf(&Block{})
	blockMapping              = queries.MakeStructMapping(blockType)
	blockPrimaryKeyMapping, _ = queries.BindMapping(blockType, blockMapping, blockPrimaryKeyColumns)
	blockInsertCacheMut       sync.RWMutex
	blockInsertCache          = make(map[string]insertCache)
	blockUpdateCacheMut       sync.RWMutex
	blockUpdateCache          = make(map[string]updateCache)
	blockUpsertCacheMut       sync.RWMutex
	blockUpsertCache          = make(map[string]insertCache)
)

var (
	// Force time package dependency for automated UpdatedAt/CreatedAt.
	_ = time.Second
	// Force bytes in case of primary key column that uses []byte (for relationship compares)
	_ = bytes.MinRead
)

// OneP returns a single Block record from the query, and panics on error.
func (q BlockQuery) OneP() *Block {
	o, err := q.One()
	if err != nil {
		panic(errors.Err(err))
	}

	return o
}

// One returns a single Block record from the query.
func (q BlockQuery) One() (*Block, error) {
	o := &Block{}

	queries.SetLimit(q.Query, 1)

	err := q.Bind(o)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			return nil, nil
		}
		return nil, errors.Prefix("model: failed to execute a one query for blocks", err)
	}

	return o, nil
}

// AllP returns all Block records from the query, and panics on error.
func (q BlockQuery) AllP() BlockSlice {
	o, err := q.All()
	if err != nil {
		panic(errors.Err(err))
	}

	return o
}

// All returns all Block records from the query.
func (q BlockQuery) All() (BlockSlice, error) {
	var o []*Block

	err := q.Bind(&o)
	if err != nil {
		return nil, errors.Prefix("model: failed to assign all query results to Block slice", err)
	}

	return o, nil
}

// CountP returns the count of all Block records in the query, and panics on error.
func (q BlockQuery) CountP() int64 {
	c, err := q.Count()
	if err != nil {
		panic(errors.Err(err))
	}

	return c
}

// Count returns the count of all Block records in the query.
func (q BlockQuery) Count() (int64, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)

	err := q.Query.QueryRow().Scan(&count)
	if err != nil {
		return 0, errors.Prefix("model: failed to count blocks rows", err)
	}

	return count, nil
}

// Exists checks if the row exists in the table, and panics on error.
func (q BlockQuery) ExistsP() bool {
	e, err := q.Exists()
	if err != nil {
		panic(errors.Err(err))
	}

	return e
}

// Exists checks if the row exists in the table.
func (q BlockQuery) Exists() (bool, error) {
	var count int64

	queries.SetCount(q.Query)
	queries.SetSelect(q.Query, []string{})
	queries.SetLimit(q.Query, 1)

	err := q.Query.QueryRow().Scan(&count)
	if err != nil {
		return false, errors.Prefix("model: failed to check if blocks exists", err)
	}

	return count > 0, nil
}

// BlockHashTransactionsG retrieves all the transaction's transactions via block_hash column.
func (o *Block) BlockHashTransactionsG(mods ...qm.QueryMod) TransactionQuery {
	return o.BlockHashTransactions(boil.GetDB(), mods...)
}

// BlockHashTransactions retrieves all the transaction's transactions with an executor via block_hash column.
func (o *Block) BlockHashTransactions(exec boil.Executor, mods ...qm.QueryMod) TransactionQuery {
	queryMods := []qm.QueryMod{
		qm.Select("`transactions`.*"),
	}

	if len(mods) != 0 {
		queryMods = append(queryMods, mods...)
	}

	queryMods = append(queryMods,
		qm.Where("`transactions`.`block_hash`=?", o.Hash),
	)

	query := Transactions(exec, queryMods...)
	queries.SetFrom(query.Query, "`transactions`")
	return query
}

// LoadBlockHashTransactions allows an eager lookup of values, cached into the
// loaded structs of the objects.
func (blockL) LoadBlockHashTransactions(e boil.Executor, singular bool, maybeBlock interface{}) error {
	var slice []*Block
	var object *Block

	count := 1
	if singular {
		object = maybeBlock.(*Block)
	} else {
		slice = *maybeBlock.(*[]*Block)
		count = len(slice)
	}

	args := make([]interface{}, count)
	if singular {
		if object.R == nil {
			object.R = &blockR{}
		}
		args[0] = object.Hash
	} else {
		for i, obj := range slice {
			if obj.R == nil {
				obj.R = &blockR{}
			}
			args[i] = obj.Hash
		}
	}

	query := fmt.Sprintf(
		"select * from `transactions` where `block_hash` in (%s)",
		strmangle.Placeholders(dialect.IndexPlaceholders, count, 1, 1),
	)
	if boil.DebugMode {
		fmt.Fprintf(boil.DebugWriter, "%s\n%v\n", query, args)
	}

	results, err := e.Query(query, args...)
	if err != nil {
		return errors.Prefix("failed to eager load transactions", err)
	}
	defer results.Close()

	var resultSlice []*Transaction
	if err = queries.Bind(results, &resultSlice); err != nil {
		return errors.Prefix("failed to bind eager loaded slice transactions", err)
	}

	if singular {
		object.R.BlockHashTransactions = resultSlice
		return nil
	}

	for _, foreign := range resultSlice {
		for _, local := range slice {
			if local.Hash == foreign.BlockHash.String {
				local.R.BlockHashTransactions = append(local.R.BlockHashTransactions, foreign)
				break
			}
		}
	}

	return nil
}

// AddBlockHashTransactionsG adds the given related objects to the existing relationships
// of the block, optionally inserting them as new records.
// Appends related to o.R.BlockHashTransactions.
// Sets related.R.BlockHash appropriately.
// Uses the global database handle.
func (o *Block) AddBlockHashTransactionsG(insert bool, related ...*Transaction) error {
	return o.AddBlockHashTransactions(boil.GetDB(), insert, related...)
}

// AddBlockHashTransactionsP adds the given related objects to the existing relationships
// of the block, optionally inserting them as new records.
// Appends related to o.R.BlockHashTransactions.
// Sets related.R.BlockHash appropriately.
// Panics on error.
func (o *Block) AddBlockHashTransactionsP(exec boil.Executor, insert bool, related ...*Transaction) {
	if err := o.AddBlockHashTransactions(exec, insert, related...); err != nil {
		panic(errors.Err(err))
	}
}

// AddBlockHashTransactionsGP adds the given related objects to the existing relationships
// of the block, optionally inserting them as new records.
// Appends related to o.R.BlockHashTransactions.
// Sets related.R.BlockHash appropriately.
// Uses the global database handle and panics on error.
func (o *Block) AddBlockHashTransactionsGP(insert bool, related ...*Transaction) {
	if err := o.AddBlockHashTransactions(boil.GetDB(), insert, related...); err != nil {
		panic(errors.Err(err))
	}
}

// AddBlockHashTransactions adds the given related objects to the existing relationships
// of the block, optionally inserting them as new records.
// Appends related to o.R.BlockHashTransactions.
// Sets related.R.BlockHash appropriately.
func (o *Block) AddBlockHashTransactions(exec boil.Executor, insert bool, related ...*Transaction) error {
	var err error
	for _, rel := range related {
		if insert {
			rel.BlockHash.String = o.Hash
			rel.BlockHash.Valid = true
			if err = rel.Insert(exec); err != nil {
				return errors.Prefix("failed to insert into foreign table", err)
			}
		} else {
			updateQuery := fmt.Sprintf(
				"UPDATE `transactions` SET %s WHERE %s",
				strmangle.SetParamNames("`", "`", 0, []string{"block_hash"}),
				strmangle.WhereClause("`", "`", 0, transactionPrimaryKeyColumns),
			)
			values := []interface{}{o.Hash, rel.ID}

			if boil.DebugMode {
				fmt.Fprintln(boil.DebugWriter, updateQuery)
				fmt.Fprintln(boil.DebugWriter, values)
			}

			if _, err = exec.Exec(updateQuery, values...); err != nil {
				return errors.Prefix("failed to update foreign table", err)
			}

			rel.BlockHash.String = o.Hash
			rel.BlockHash.Valid = true
		}
	}

	if o.R == nil {
		o.R = &blockR{
			BlockHashTransactions: related,
		}
	} else {
		o.R.BlockHashTransactions = append(o.R.BlockHashTransactions, related...)
	}

	for _, rel := range related {
		if rel.R == nil {
			rel.R = &transactionR{
				BlockHash: o,
			}
		} else {
			rel.R.BlockHash = o
		}
	}
	return nil
}

// SetBlockHashTransactionsG removes all previously related items of the
// block replacing them completely with the passed
// in related items, optionally inserting them as new records.
// Sets o.R.BlockHash's BlockHashTransactions accordingly.
// Replaces o.R.BlockHashTransactions with related.
// Sets related.R.BlockHash's BlockHashTransactions accordingly.
// Uses the global database handle.
func (o *Block) SetBlockHashTransactionsG(insert bool, related ...*Transaction) error {
	return o.SetBlockHashTransactions(boil.GetDB(), insert, related...)
}

// SetBlockHashTransactionsP removes all previously related items of the
// block replacing them completely with the passed
// in related items, optionally inserting them as new records.
// Sets o.R.BlockHash's BlockHashTransactions accordingly.
// Replaces o.R.BlockHashTransactions with related.
// Sets related.R.BlockHash's BlockHashTransactions accordingly.
// Panics on error.
func (o *Block) SetBlockHashTransactionsP(exec boil.Executor, insert bool, related ...*Transaction) {
	if err := o.SetBlockHashTransactions(exec, insert, related...); err != nil {
		panic(errors.Err(err))
	}
}

// SetBlockHashTransactionsGP removes all previously related items of the
// block replacing them completely with the passed
// in related items, optionally inserting them as new records.
// Sets o.R.BlockHash's BlockHashTransactions accordingly.
// Replaces o.R.BlockHashTransactions with related.
// Sets related.R.BlockHash's BlockHashTransactions accordingly.
// Uses the global database handle and panics on error.
func (o *Block) SetBlockHashTransactionsGP(insert bool, related ...*Transaction) {
	if err := o.SetBlockHashTransactions(boil.GetDB(), insert, related...); err != nil {
		panic(errors.Err(err))
	}
}

// SetBlockHashTransactions removes all previously related items of the
// block replacing them completely with the passed
// in related items, optionally inserting them as new records.
// Sets o.R.BlockHash's BlockHashTransactions accordingly.
// Replaces o.R.BlockHashTransactions with related.
// Sets related.R.BlockHash's BlockHashTransactions accordingly.
func (o *Block) SetBlockHashTransactions(exec boil.Executor, insert bool, related ...*Transaction) error {
	query := "update `transactions` set `block_hash` = null where `block_hash` = ?"
	values := []interface{}{o.Hash}
	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, query)
		fmt.Fprintln(boil.DebugWriter, values)
	}

	_, err := exec.Exec(query, values...)
	if err != nil {
		return errors.Prefix("failed to remove relationships before set", err)
	}

	if o.R != nil {
		for _, rel := range o.R.BlockHashTransactions {
			rel.BlockHash.Valid = false
			if rel.R == nil {
				continue
			}

			rel.R.BlockHash = nil
		}

		o.R.BlockHashTransactions = nil
	}
	return o.AddBlockHashTransactions(exec, insert, related...)
}

// RemoveBlockHashTransactionsG relationships from objects passed in.
// Removes related items from R.BlockHashTransactions (uses pointer comparison, removal does not keep order)
// Sets related.R.BlockHash.
// Uses the global database handle.
func (o *Block) RemoveBlockHashTransactionsG(related ...*Transaction) error {
	return o.RemoveBlockHashTransactions(boil.GetDB(), related...)
}

// RemoveBlockHashTransactionsP relationships from objects passed in.
// Removes related items from R.BlockHashTransactions (uses pointer comparison, removal does not keep order)
// Sets related.R.BlockHash.
// Panics on error.
func (o *Block) RemoveBlockHashTransactionsP(exec boil.Executor, related ...*Transaction) {
	if err := o.RemoveBlockHashTransactions(exec, related...); err != nil {
		panic(errors.Err(err))
	}
}

// RemoveBlockHashTransactionsGP relationships from objects passed in.
// Removes related items from R.BlockHashTransactions (uses pointer comparison, removal does not keep order)
// Sets related.R.BlockHash.
// Uses the global database handle and panics on error.
func (o *Block) RemoveBlockHashTransactionsGP(related ...*Transaction) {
	if err := o.RemoveBlockHashTransactions(boil.GetDB(), related...); err != nil {
		panic(errors.Err(err))
	}
}

// RemoveBlockHashTransactions relationships from objects passed in.
// Removes related items from R.BlockHashTransactions (uses pointer comparison, removal does not keep order)
// Sets related.R.BlockHash.
func (o *Block) RemoveBlockHashTransactions(exec boil.Executor, related ...*Transaction) error {
	var err error
	for _, rel := range related {
		rel.BlockHash.Valid = false
		if rel.R != nil {
			rel.R.BlockHash = nil
		}
		if err = rel.Update(exec, "block_hash"); err != nil {
			return errors.Err(err)
		}
	}
	if o.R == nil {
		return nil
	}

	for _, rel := range related {
		for i, ri := range o.R.BlockHashTransactions {
			if rel != ri {
				continue
			}

			ln := len(o.R.BlockHashTransactions)
			if ln > 1 && i < ln-1 {
				o.R.BlockHashTransactions[i] = o.R.BlockHashTransactions[ln-1]
			}
			o.R.BlockHashTransactions = o.R.BlockHashTransactions[:ln-1]
			break
		}
	}

	return nil
}

// BlocksG retrieves all records.
func BlocksG(mods ...qm.QueryMod) BlockQuery {
	return Blocks(boil.GetDB(), mods...)
}

// Blocks retrieves all the records using an executor.
func Blocks(exec boil.Executor, mods ...qm.QueryMod) BlockQuery {
	mods = append(mods, qm.From("`blocks`"))
	return BlockQuery{NewQuery(exec, mods...)}
}

// FindBlockG retrieves a single record by ID.
func FindBlockG(id uint64, selectCols ...string) (*Block, error) {
	return FindBlock(boil.GetDB(), id, selectCols...)
}

// FindBlockGP retrieves a single record by ID, and panics on error.
func FindBlockGP(id uint64, selectCols ...string) *Block {
	retobj, err := FindBlock(boil.GetDB(), id, selectCols...)
	if err != nil {
		panic(errors.Err(err))
	}

	return retobj
}

// FindBlock retrieves a single record by ID with an executor.
// If selectCols is empty Find will return all columns.
func FindBlock(exec boil.Executor, id uint64, selectCols ...string) (*Block, error) {
	blockObj := &Block{}

	sel := "*"
	if len(selectCols) > 0 {
		sel = strings.Join(strmangle.IdentQuoteSlice(dialect.LQ, dialect.RQ, selectCols), ",")
	}
	query := fmt.Sprintf(
		"select %s from `blocks` where `id`=?", sel,
	)

	q := queries.Raw(exec, query, id)

	err := q.Bind(blockObj)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			return nil, nil
		}
		return nil, errors.Prefix("model: unable to select from blocks", err)
	}

	return blockObj, nil
}

// FindBlockP retrieves a single record by ID with an executor, and panics on error.
func FindBlockP(exec boil.Executor, id uint64, selectCols ...string) *Block {
	retobj, err := FindBlock(exec, id, selectCols...)
	if err != nil {
		panic(errors.Err(err))
	}

	return retobj
}

// FindOneBlock retrieves a single record using filters.
func FindOneBlock(exec boil.Executor, filters BlockFilter) (*Block, error) {
	obj := &Block{}

	err := BlockNewQuery(exec).
		Where(filters).
		Limit(1).
		Bind(obj)

	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			return nil, nil
		}
		return nil, errors.Prefix("model: unable to select from blocks", err)
	}

	return obj, nil
}

// FindOneBlockG retrieves a single record using filters.
func FindOneBlockG(filters BlockFilter) (*Block, error) {
	return FindOneBlock(boil.GetDB(), filters)
}

// FindOneBlockOrInit retrieves a single record using filters, or initializes a new record if one is not found.
func FindOneBlockOrInit(exec boil.Executor, filters BlockFilter) (*Block, error) {
	blockObj, err := FindOneBlock(exec, filters)
	if err != nil {
		return nil, err
	}

	if blockObj == nil {
		blockObj = &Block{}
		objR := reflect.ValueOf(blockObj).Elem()
		r := reflect.ValueOf(filters)
		for i := 0; i < r.NumField(); i++ {
			f := r.Field(i)
			if f.Elem().IsValid() {
				objR.FieldByName(r.Type().Field(i).Name).Set(f.Elem())
			}
		}
	}

	return blockObj, nil
}

// FindOneBlockOrInit retrieves a single record using filters, or initializes a new record if one is not found.
func FindOneBlockOrInitG(filters BlockFilter) (*Block, error) {
	return FindOneBlockOrInit(boil.GetDB(), filters)
}

// FindOneBlockOrInit retrieves a single record using filters, or initializes and inserts a new record if one is not found.
func FindOneBlockOrCreate(exec boil.Executor, filters BlockFilter) (*Block, error) {
	blockObj, err := FindOneBlockOrInit(exec, filters)
	if err != nil {
		return nil, err
	}
	if blockObj.IsNew() {
		err := blockObj.Insert(exec)
		if err != nil {
			return nil, err
		}
	}
	return blockObj, nil
}

// FindOneBlockOrInit retrieves a single record using filters, or initializes and inserts a new record if one is not found.
func FindOneBlockOrCreateG(filters BlockFilter) (*Block, error) {
	return FindOneBlockOrCreate(boil.GetDB(), filters)
}

// InsertG a single record. See Insert for whitelist behavior description.
func (o *Block) InsertG(whitelist ...string) error {
	return o.Insert(boil.GetDB(), whitelist...)
}

// InsertGP a single record, and panics on error. See Insert for whitelist
// behavior description.
func (o *Block) InsertGP(whitelist ...string) {
	if err := o.Insert(boil.GetDB(), whitelist...); err != nil {
		panic(errors.Err(err))
	}
}

// InsertP a single record using an executor, and panics on error. See Insert
// for whitelist behavior description.
func (o *Block) InsertP(exec boil.Executor, whitelist ...string) {
	if err := o.Insert(exec, whitelist...); err != nil {
		panic(errors.Err(err))
	}
}

// Insert a single record using an executor.
// Whitelist behavior: If a whitelist is provided, only those columns supplied are inserted
// No whitelist behavior: Without a whitelist, columns are inferred by the following rules:
// - All columns without a default value are included (i.e. name, age)
// - All columns with a default, but non-zero are included (i.e. health = 75)
func (o *Block) Insert(exec boil.Executor, whitelist ...string) error {
	if o == nil {
		return errors.Err("model: no blocks provided for insertion")
	}

	var err error

	nzDefaults := queries.NonZeroDefaultSet(blockColumnsWithDefault, o)

	key := makeCacheKey(whitelist, nzDefaults)
	blockInsertCacheMut.RLock()
	cache, cached := blockInsertCache[key]
	blockInsertCacheMut.RUnlock()

	if !cached {
		wl, returnColumns := strmangle.InsertColumnSet(
			blockColumns,
			blockColumnsWithDefault,
			blockColumnsWithoutDefault,
			nzDefaults,
			whitelist,
		)

		cache.valueMapping, err = queries.BindMapping(blockType, blockMapping, wl)
		if err != nil {
			return errors.Err(err)
		}
		cache.retMapping, err = queries.BindMapping(blockType, blockMapping, returnColumns)
		if err != nil {
			return errors.Err(err)
		}
		if len(wl) != 0 {
			cache.query = fmt.Sprintf("INSERT INTO `blocks` (`%s`) %%sVALUES (%s)%%s", strings.Join(wl, "`,`"), strmangle.Placeholders(dialect.IndexPlaceholders, len(wl), 1, 1))
		} else {
			cache.query = "INSERT INTO `blocks` () VALUES ()"
		}

		var queryOutput, queryReturning string

		if len(cache.retMapping) != 0 {
			cache.retQuery = fmt.Sprintf("SELECT `%s` FROM `blocks` WHERE %s", strings.Join(returnColumns, "`,`"), strmangle.WhereClause("`", "`", 0, blockPrimaryKeyColumns))
		}

		if len(wl) != 0 {
			cache.query = fmt.Sprintf(cache.query, queryOutput, queryReturning)
		}
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, cache.query)
		fmt.Fprintln(boil.DebugWriter, vals)
	}

	result, err := exec.Exec(cache.query, vals...)

	if err != nil {
		return errors.Prefix("model: unable to insert into blocks", err)
	}

	var lastID int64
	var identifierCols []interface{}

	if len(cache.retMapping) == 0 {
		goto CacheNoHooks
	}

	lastID, err = result.LastInsertId()
	if err != nil {
		return errors.Err(ErrSyncFail)
	}

	o.ID = uint64(lastID)
	if lastID != 0 && len(cache.retMapping) == 1 && cache.retMapping[0] == blockMapping["ID"] {
		goto CacheNoHooks
	}

	identifierCols = []interface{}{
		o.ID,
	}

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, cache.retQuery)
		fmt.Fprintln(boil.DebugWriter, identifierCols...)
	}

	err = exec.QueryRow(cache.retQuery, identifierCols...).Scan(queries.PtrsFromMapping(value, cache.retMapping)...)
	if err != nil {
		return errors.Prefix("model: unable to populate default values for blocks", err)
	}

CacheNoHooks:
	if !cached {
		blockInsertCacheMut.Lock()
		blockInsertCache[key] = cache
		blockInsertCacheMut.Unlock()
	}

	return nil
}

// UpdateG a single Block record. See Update for
// whitelist behavior description.
func (o *Block) UpdateG(whitelist ...string) error {
	return o.Update(boil.GetDB(), whitelist...)
}

// UpdateGP a single Block record.
// UpdateGP takes a whitelist of column names that should be updated.
// Panics on error. See Update for whitelist behavior description.
func (o *Block) UpdateGP(whitelist ...string) {
	if err := o.Update(boil.GetDB(), whitelist...); err != nil {
		panic(errors.Err(err))
	}
}

// UpdateP uses an executor to update the Block, and panics on error.
// See Update for whitelist behavior description.
func (o *Block) UpdateP(exec boil.Executor, whitelist ...string) {
	err := o.Update(exec, whitelist...)
	if err != nil {
		panic(errors.Err(err))
	}
}

// Update uses an executor to update the Block.
// Whitelist behavior: If a whitelist is provided, only the columns given are updated.
// No whitelist behavior: Without a whitelist, columns are inferred by the following rules:
// - All columns are inferred to start with
// - All primary keys are subtracted from this set
// Update does not automatically update the record in case of default values. Use .Reload()
// to refresh the records.
func (o *Block) Update(exec boil.Executor, whitelist ...string) error {
	var err error
	key := makeCacheKey(whitelist, nil)
	blockUpdateCacheMut.RLock()
	cache, cached := blockUpdateCache[key]
	blockUpdateCacheMut.RUnlock()

	if !cached {
		wl := strmangle.UpdateColumnSet(
			blockColumns,
			blockPrimaryKeyColumns,
			whitelist,
		)

		if len(wl) == 0 {
			return errors.Err("model: unable to update blocks, could not build whitelist")
		}

		cache.query = fmt.Sprintf("UPDATE `blocks` SET %s WHERE %s",
			strmangle.SetParamNames("`", "`", 0, wl),
			strmangle.WhereClause("`", "`", 0, blockPrimaryKeyColumns),
		)
		cache.valueMapping, err = queries.BindMapping(blockType, blockMapping, append(wl, blockPrimaryKeyColumns...))
		if err != nil {
			return errors.Err(err)
		}
	}

	values := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), cache.valueMapping)

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, cache.query)
		fmt.Fprintln(boil.DebugWriter, values)
	}

	_, err = exec.Exec(cache.query, values...)
	if err != nil {
		return errors.Prefix("model: unable to update blocks row", err)
	}

	if !cached {
		blockUpdateCacheMut.Lock()
		blockUpdateCache[key] = cache
		blockUpdateCacheMut.Unlock()
	}

	return nil
}

// UpdateAllP updates all rows with matching column names, and panics on error.
func (q BlockQuery) UpdateAllP(cols M) {
	if err := q.UpdateAll(cols); err != nil {
		panic(errors.Err(err))
	}
}

// UpdateAll updates all rows with the specified column values.
func (q BlockQuery) UpdateAll(cols M) error {
	queries.SetUpdate(q.Query, cols)

	_, err := q.Query.Exec()
	if err != nil {
		return errors.Prefix("model: unable to update all for blocks", err)
	}

	return nil
}

// UpdateAllG updates all rows with the specified column values.
func (o BlockSlice) UpdateAllG(cols M) error {
	return o.UpdateAll(boil.GetDB(), cols)
}

// UpdateAllGP updates all rows with the specified column values, and panics on error.
func (o BlockSlice) UpdateAllGP(cols M) {
	if err := o.UpdateAll(boil.GetDB(), cols); err != nil {
		panic(errors.Err(err))
	}
}

// UpdateAllP updates all rows with the specified column values, and panics on error.
func (o BlockSlice) UpdateAllP(exec boil.Executor, cols M) {
	if err := o.UpdateAll(exec, cols); err != nil {
		panic(errors.Err(err))
	}
}

// UpdateAll updates all rows with the specified column values, using an executor.
func (o BlockSlice) UpdateAll(exec boil.Executor, cols M) error {
	ln := int64(len(o))
	if ln == 0 {
		return nil
	}

	if len(cols) == 0 {
		return errors.Err("model: update all requires at least one column argument")
	}

	colNames := make([]string, len(cols))
	args := make([]interface{}, len(cols))

	i := 0
	for name, value := range cols {
		colNames[i] = name
		args[i] = value
		i++
	}

	// Append all of the primary key values for each column
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), blockPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := fmt.Sprintf("UPDATE `blocks` SET %s WHERE %s",
		strmangle.SetParamNames("`", "`", 0, colNames),
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, blockPrimaryKeyColumns, len(o)))

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, sql)
		fmt.Fprintln(boil.DebugWriter, args...)
	}

	_, err := exec.Exec(sql, args...)
	if err != nil {
		return errors.Prefix("model: unable to update all in block slice", err)
	}

	return nil
}

// UpsertG attempts an insert, and does an update or ignore on conflict.
func (o *Block) UpsertG(updateColumns []string, whitelist ...string) error {
	return o.Upsert(boil.GetDB(), updateColumns, whitelist...)
}

// UpsertGP attempts an insert, and does an update or ignore on conflict. Panics on error.
func (o *Block) UpsertGP(updateColumns []string, whitelist ...string) {
	if err := o.Upsert(boil.GetDB(), updateColumns, whitelist...); err != nil {
		panic(errors.Err(err))
	}
}

// UpsertP attempts an insert using an executor, and does an update or ignore on conflict.
// UpsertP panics on error.
func (o *Block) UpsertP(exec boil.Executor, updateColumns []string, whitelist ...string) {
	if err := o.Upsert(exec, updateColumns, whitelist...); err != nil {
		panic(errors.Err(err))
	}
}

// Upsert attempts an insert using an executor, and does an update or ignore on conflict.
func (o *Block) Upsert(exec boil.Executor, updateColumns []string, whitelist ...string) error {
	if o == nil {
		return errors.Err("model: no blocks provided for upsert")
	}

	nzDefaults := queries.NonZeroDefaultSet(blockColumnsWithDefault, o)

	// Build cache key in-line uglily - mysql vs postgres problems
	buf := strmangle.GetBuffer()
	for _, c := range updateColumns {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	for _, c := range whitelist {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	for _, c := range nzDefaults {
		buf.WriteString(c)
	}
	key := buf.String()
	strmangle.PutBuffer(buf)

	blockUpsertCacheMut.RLock()
	cache, cached := blockUpsertCache[key]
	blockUpsertCacheMut.RUnlock()

	var err error

	if !cached {
		insert, ret := strmangle.InsertColumnSet(
			blockColumns,
			blockColumnsWithDefault,
			blockColumnsWithoutDefault,
			nzDefaults,
			whitelist,
		)

		update := strmangle.UpdateColumnSet(
			blockColumns,
			blockPrimaryKeyColumns,
			updateColumns,
		)
		if len(update) == 0 {
			return errors.Err("model: unable to upsert blocks, could not build update column list")
		}

		cache.query = queries.BuildUpsertQueryMySQL(dialect, "blocks", update, insert, blockAutoIncrementColumn)
		cache.retQuery = fmt.Sprintf(
			"SELECT %s FROM `blocks` WHERE `id`=?",
			strings.Join(strmangle.IdentQuoteSlice(dialect.LQ, dialect.RQ, ret), ","),
		)

		cache.valueMapping, err = queries.BindMapping(blockType, blockMapping, insert)
		if err != nil {
			return errors.Err(err)
		}
		if len(ret) != 0 {
			cache.retMapping, err = queries.BindMapping(blockType, blockMapping, ret)
			if err != nil {
				return errors.Err(err)
			}
		}
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)
	var returns []interface{}
	if len(cache.retMapping) != 0 {
		returns = queries.PtrsFromMapping(value, cache.retMapping)
	}

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, cache.query)
		fmt.Fprintln(boil.DebugWriter, vals)
	}

	result, err := exec.Exec(cache.query, vals...)

	if err != nil {
		return errors.Prefix("model: unable to upsert for blocks", err)
	}

	var lastID int64
	var identifierCols []interface{}

	if len(cache.retMapping) == 0 {
		goto CacheNoHooks
	}

	lastID, err = result.LastInsertId()
	if err != nil {
		return errors.Err(ErrSyncFail)
	}

	o.ID = uint64(lastID)
	if lastID != 0 && len(cache.retMapping) == 1 && cache.retMapping[0] == blockMapping["ID"] {
		goto CacheNoHooks
	}

	identifierCols = []interface{}{
		o.ID,
	}

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, cache.retQuery)
		fmt.Fprintln(boil.DebugWriter, identifierCols...)
	}

	err = exec.QueryRow(cache.retQuery, identifierCols...).Scan(returns...)
	if err != nil {
		return errors.Prefix("model: unable to populate default values for blocks", err)
	}

CacheNoHooks:
	if !cached {
		blockUpsertCacheMut.Lock()
		blockUpsertCache[key] = cache
		blockUpsertCacheMut.Unlock()
	}

	return nil
}

// DeleteP deletes a single Block record with an executor.
// DeleteP will match against the primary key column to find the record to delete.
// Panics on error.
func (o *Block) DeleteP(exec boil.Executor) {
	if err := o.Delete(exec); err != nil {
		panic(errors.Err(err))
	}
}

// DeleteG deletes a single Block record.
// DeleteG will match against the primary key column to find the record to delete.
func (o *Block) DeleteG() error {
	if o == nil {
		return errors.Err("model: no Block provided for deletion")
	}

	return o.Delete(boil.GetDB())
}

// DeleteGP deletes a single Block record.
// DeleteGP will match against the primary key column to find the record to delete.
// Panics on error.
func (o *Block) DeleteGP() {
	if err := o.DeleteG(); err != nil {
		panic(errors.Err(err))
	}
}

// Delete deletes a single Block record with an executor.
// Delete will match against the primary key column to find the record to delete.
func (o *Block) Delete(exec boil.Executor) error {
	if o == nil {
		return errors.Err("model: no Block provided for delete")
	}

	args := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), blockPrimaryKeyMapping)
	sql := "DELETE FROM `blocks` WHERE `id`=?"

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, sql)
		fmt.Fprintln(boil.DebugWriter, args...)
	}

	_, err := exec.Exec(sql, args...)
	if err != nil {
		return errors.Prefix("model: unable to delete from blocks", err)
	}

	return nil
}

// DeleteAllP deletes all rows, and panics on error.
func (q BlockQuery) DeleteAllP() {
	if err := q.DeleteAll(); err != nil {
		panic(errors.Err(err))
	}
}

// DeleteAll deletes all matching rows.
func (q BlockQuery) DeleteAll() error {
	if q.Query == nil {
		return errors.Err("model: no BlockQuery provided for delete all")
	}

	queries.SetDelete(q.Query)

	_, err := q.Query.Exec()
	if err != nil {
		return errors.Prefix("model: unable to delete all from blocks", err)
	}

	return nil
}

// DeleteAllGP deletes all rows in the slice, and panics on error.
func (o BlockSlice) DeleteAllGP() {
	if err := o.DeleteAllG(); err != nil {
		panic(errors.Err(err))
	}
}

// DeleteAllG deletes all rows in the slice.
func (o BlockSlice) DeleteAllG() error {
	if o == nil {
		return errors.Err("model: no Block slice provided for delete all")
	}
	return o.DeleteAll(boil.GetDB())
}

// DeleteAllP deletes all rows in the slice, using an executor, and panics on error.
func (o BlockSlice) DeleteAllP(exec boil.Executor) {
	if err := o.DeleteAll(exec); err != nil {
		panic(errors.Err(err))
	}
}

// DeleteAll deletes all rows in the slice, using an executor.
func (o BlockSlice) DeleteAll(exec boil.Executor) error {
	if o == nil {
		return errors.Err("model: no Block slice provided for delete all")
	}

	if len(o) == 0 {
		return nil
	}

	var args []interface{}
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), blockPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "DELETE FROM `blocks` WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, blockPrimaryKeyColumns, len(o))

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, sql)
		fmt.Fprintln(boil.DebugWriter, args)
	}

	_, err := exec.Exec(sql, args...)
	if err != nil {
		return errors.Prefix("model: unable to delete all from block slice", err)
	}

	return nil
}

// ReloadGP refetches the object from the database and panics on error.
func (o *Block) ReloadGP() {
	if err := o.ReloadG(); err != nil {
		panic(errors.Err(err))
	}
}

// ReloadP refetches the object from the database with an executor. Panics on error.
func (o *Block) ReloadP(exec boil.Executor) {
	if err := o.Reload(exec); err != nil {
		panic(errors.Err(err))
	}
}

// ReloadG refetches the object from the database using the primary keys.
func (o *Block) ReloadG() error {
	if o == nil {
		return errors.Err("model: no Block provided for reload")
	}

	return o.Reload(boil.GetDB())
}

// Reload refetches the object from the database
// using the primary keys with an executor.
func (o *Block) Reload(exec boil.Executor) error {
	ret, err := FindBlock(exec, o.ID)
	if err != nil {
		return errors.Err(err)
	}

	*o = *ret
	return nil
}

// ReloadAllGP refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
// Panics on error.
func (o *BlockSlice) ReloadAllGP() {
	if err := o.ReloadAllG(); err != nil {
		panic(errors.Err(err))
	}
}

// ReloadAllP refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
// Panics on error.
func (o *BlockSlice) ReloadAllP(exec boil.Executor) {
	if err := o.ReloadAll(exec); err != nil {
		panic(errors.Err(err))
	}
}

// ReloadAllG refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
func (o *BlockSlice) ReloadAllG() error {
	if o == nil {
		return errors.Err("model: empty BlockSlice provided for reload all")
	}

	return o.ReloadAll(boil.GetDB())
}

// ReloadAll refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
func (o *BlockSlice) ReloadAll(exec boil.Executor) error {
	if o == nil || len(*o) == 0 {
		return nil
	}

	blocks := BlockSlice{}
	var args []interface{}
	for _, obj := range *o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), blockPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "SELECT `blocks`.* FROM `blocks` WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, blockPrimaryKeyColumns, len(*o))

	q := queries.Raw(exec, sql, args...)

	err := q.Bind(&blocks)
	if err != nil {
		return errors.Prefix("model: unable to reload all in BlockSlice", err)
	}

	*o = blocks

	return nil
}

// BlockExists checks if the Block row exists.
func BlockExists(exec boil.Executor, id uint64) (bool, error) {
	var exists bool
	sql := "select exists(select 1 from `blocks` where `id`=? limit 1)"

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, sql)
		fmt.Fprintln(boil.DebugWriter, id)
	}

	row := exec.QueryRow(sql, id)

	err := row.Scan(&exists)
	if err != nil {
		return false, errors.Prefix("model: unable to check if blocks exists", err)
	}

	return exists, nil
}

// BlockExistsG checks if the Block row exists.
func BlockExistsG(id uint64) (bool, error) {
	return BlockExists(boil.GetDB(), id)
}

// BlockExistsGP checks if the Block row exists. Panics on error.
func BlockExistsGP(id uint64) bool {
	e, err := BlockExists(boil.GetDB(), id)
	if err != nil {
		panic(errors.Err(err))
	}

	return e
}

// BlockExistsP checks if the Block row exists. Panics on error.
func BlockExistsP(exec boil.Executor, id uint64) bool {
	e, err := BlockExists(exec, id)
	if err != nil {
		panic(errors.Err(err))
	}

	return e
}

// IsNew() checks if record exists in db (aka if its primary key is set).
func (o *Block) IsNew() bool {
	r := reflect.ValueOf(o).Elem()
	for i := 0; i < r.NumField(); i++ {
		column := r.Type().Field(i).Tag.Get("boil")
		for _, pkColumn := range blockPrimaryKeyColumns {
			if column == pkColumn {
				field := r.Field(i)
				if field.Interface() != reflect.Zero(field.Type()).Interface() {
					return false
				}
			}
		}
	}
	return true
}

// Save() inserts the record if it does not exist, or updates it if it does.
func (o *Block) Save(exec boil.Executor, whitelist ...string) error {
	if o.IsNew() {
		return o.Insert(exec, whitelist...)
	} else {
		return o.Update(exec, whitelist...)
	}
}

// SaveG() inserts the record if it does not exist, or updates it if it does.
func (o *Block) SaveG(whitelist ...string) error {
	if o.IsNew() {
		return o.InsertG(whitelist...)
	} else {
		return o.UpdateG(whitelist...)
	}
}

// BlockNewQuery filters query results
func BlockNewQuery(exec boil.Executor) *BlockQuery {
	return &BlockQuery{NewQuery(exec, qm.Select("*"), qm.From("`blocks`"))}
}

// BlockNewQuery filters query results
func BlockNewQueryG() *BlockQuery {
	return BlockNewQuery(boil.GetDB())
}

// Where filters query results
func (q *BlockQuery) Where(filters BlockFilter) *BlockQuery {
	r := reflect.ValueOf(filters)
	for i := 0; i < r.NumField(); i++ {
		f := r.Field(i)
		if f.Elem().IsValid() {
			if nullable, ok := f.Elem().Interface().(null.Nullable); ok && nullable.IsNull() {
				queries.AppendWhere(q.Query, r.Type().Field(i).Tag.Get("boil")+" IS NULL")
			} else {
				queries.AppendWhere(q.Query, r.Type().Field(i).Tag.Get("boil")+" = ?", f.Elem().Interface())
			}
		}
	}
	return q
}

// Limit limits query results
func (q *BlockQuery) Limit(limit int) *BlockQuery {
	queries.SetLimit(q.Query, limit)
	return q
}

// Merge combines two Blocks into one. The primary record will be kept, and the secondary will be deleted.
func MergeBlocks(exec boil.Executor, primaryID uint64, secondaryID uint64) (err error) {
	tx, ok := exec.(boil.Transactor)
	if !ok {
		txdb, ok := exec.(boil.Beginner)
		if !ok {
			return errors.Err("database does not support transactions")
		}

		tx, err = txdb.Begin()
		if err != nil {
			return errors.Err(err)
		}

		defer func() {
			if p := recover(); p != nil {
				tx.Rollback()
				panic(p) // Rollback, then propagate panic
			} else if err != nil {
				tx.Rollback()
			} else {
				err = tx.Commit()
			}
		}()
	}

	primary, err := FindBlock(tx, primaryID)
	if err != nil {
		return errors.Err(err)
	} else if primary == nil {
		return errors.Err("primary Block not found")
	}

	secondary, err := FindBlock(tx, secondaryID)
	if err != nil {
		return errors.Err(err)
	} else if secondary == nil {
		return errors.Err("secondary Block not found")
	}

	foreignKeys := []foreignKey{
		{foreignTable: "transactions", foreignColumn: "block_hash"},
	}

	conflictingKeys := []conflictingUniqueKey{}

	err = mergeModels(tx, primaryID, secondaryID, foreignKeys, conflictingKeys)
	if err != nil {
		return err
	}

	pr := reflect.ValueOf(primary)
	sr := reflect.ValueOf(secondary)
	// for any column thats null on the primary and not null on the secondary, copy from secondary to primary
	for i := 0; i < sr.Elem().NumField(); i++ {
		pf := pr.Elem().Field(i)
		sf := sr.Elem().Field(i)
		if sf.IsValid() {
			if nullable, ok := sf.Interface().(null.Nullable); ok && !nullable.IsNull() && pf.Interface().(null.Nullable).IsNull() {
				pf.Set(sf)
			}
		}
	}

	err = primary.Update(tx)
	if err != nil {
		return err
	}

	err = secondary.Delete(tx)
	if err != nil {
		return err
	}

	return nil
}

// Merge combines two Blocks into one. The primary record will be kept, and the secondary will be deleted.
func MergeBlocksG(primaryID uint64, secondaryID uint64) error {
	return MergeBlocks(boil.GetDB(), primaryID, secondaryID)
}
